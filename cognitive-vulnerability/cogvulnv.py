import argparse
import cProfile
import logging
import pandas as pd
import random
import re

from psychsim.world import World
from psychsim.agent import Agent
from psychsim.probability import Distribution
from psychsim.pwl.keys import stateKey, makeFuture, modelKey
from psychsim.pwl.vector import KeyedVector
from psychsim.pwl.plane import equalRow, trueRow, thresholdRow
from psychsim.pwl.matrix import approachMatrix, setToFeatureMatrix, noChangeMatrix, setToConstantMatrix, setTrueMatrix, setFalseMatrix
from psychsim.pwl.tree import makeTree
from psychsim.reward import pwl_goal, achieve_goal

class Attacker(Agent):
    """
    Attacker agent modeled as a PsychSim agent
    """
    CogVulns = [# 'availability',
                'base_rate', 
                # 'confirmation',
                'loss_aversion', 
                'sunk_cost'
                ]

    def __init__(self, name, world, stochastic=True, **kwargs):
        super().__init__(name, world)
        self.color = '#ff0044'
        self.R_gains = kwargs.get('reward', 0)
        world.add_agent(self)
        # Decision-making attributes
        self.setAttribute('horizon', 1)
        if stochastic:
            self.setAttribute('selection', 'distribution')
            self.setAttribute('rationality', 5)
        world.define_state(self.name, 'discovered', bool, default=False)
        # Cognitive vulnerabilities
        self.cogvulns = {}
        for cogvuln in self.CogVulns:
            self.cogvulns[cogvuln] = world.defineState(name, cogvuln)
            world.set_feature(self.cogvulns[cogvuln], kwargs.get(cogvuln, 0))
        self.targets = None
        # noop action
        self.noop = self.add_action({'verb': 'noop'})
        # self.setLegal(self.noop, makeTree(False))

    def finalize(self, targets, reward, model=None):
        """Sets the reward that this agent will get for achieving the final state
        """
        self.targets = targets
        self.set_goals(reward)
        self.finalize_beliefs(model)
        self.set_observations({t.value for t in self.targets} | 
                              {t.difficulty for t in self.targets})

    def finalize_beliefs(self, model=None):
        # Attacker's initial beliefs
        if model is None:
            model = self.get_true_model()
        self.create_belief_state(model=model, 
                                 ignore={modelKey(self.world.blue.name)})
        for target in self.targets:
            self.set_belief(target.value, 
                            Distribution({0.75: 0.7, 0.25: 0.3}), model)
            self.set_belief(target.difficulty, 
                            Distribution({0.75: 0.3, 0.25: 0.7}), model)
        if model != self.get_true_model():
            cogvuln = '_'.join(model.split('_')[1:])
            for hypothesis in self.cogvulns:
                self.set_belief(stateKey(self.name, hypothesis), 1 if cogvuln == hypothesis else 0, model)

    def set_goals(self, reward, model=None):
        if model is None:
            self.R_gains = reward
        goal = achieve_goal(stateKey(self.name, 'discovered'), self.name, 
                            invert=True)
        self.setReward(goal, .1, model=model)
        goal = pwl_goal(self.name, KeyedVector({host.exploits: 1 for host in self.targets}))
        self.setReward(goal, reward, model=model)

    def add_host(self, host):
        # Add all possible actions
        legality = {}
        for s_i, table in host.transition_matrix.items():
            for verb, transition in table.items():
                a = self.add_action({'verb': verb, 'object': host.name})
                legality[a] = legality.get(a, []) + [s_i]
        actions = []
        # Add legality restrictions, when appropriate
        for a, states in legality.items():
            tree = makeTree({'if': equalRow(host.progress, states[0] if len(states) == 1
                                            else set(states)),
                             True: True, False: False})
            self.setLegal(a, tree)
            actions.append(a)
        # Dynamics of actions
        #self.world.setDynamics(host.progress, self.noop, makeTree(setToConstantMatrix(host.progress, 'K')))
        self.world.setDynamics(host.progress, self.noop, makeTree(noChangeMatrix(host.progress)))

        for a in actions:
            if a in legality:
                # Effect on red team progress
                states = legality[a]
                tree = {'if': equalRow(host.progress, states),
                        None: noChangeMatrix(host.progress)}
                for s_i in legality[a]:
                    s_f, p = host.transition_matrix[s_i][a['verb']]
                    if p == 1:
                        subtree = setToConstantMatrix(host.progress, s_f)
                    else:
                        subtree = {'if': trueRow(host.difficulty),
                                   True: Distribution({setToConstantMatrix(host.progress, s_f): p/2,
                                                       noChangeMatrix(host.progress): 1-p/2}),
                                   False: Distribution({setToConstantMatrix(host.progress, s_f): p,
                                                        noChangeMatrix(host.progress): 1-p})}
                    if a['verb'] == 'PE' and 'base_rate' in self.cogvulns:
                        subtree[True] = {'if': thresholdRow(self.cogvulns['base_rate'], 0.5),
                                         True: Distribution({setToConstantMatrix(host.progress, s_f): p,
                                                             noChangeMatrix(host.progress): 1-p}),
                                         False: subtree[True]}
                        subtree[False] = {'if': thresholdRow(self.cogvulns['base_rate'], 0.5),
                                          True: Distribution({setToConstantMatrix(host.progress, s_f): p*1.5,
                                                              noChangeMatrix(host.progress): 1-p*1.5}),
                                          False: subtree[False]}
                        
                    if a['verb'] == 'ASD' and 'base_rate' in self.cogvulns:
                        subtree[True] = {'if': thresholdRow(self.cogvulns['base_rate'], 0.5),
                                         True: Distribution({setToConstantMatrix(host.progress, s_f): p,
                                                             noChangeMatrix(host.progress): 1-p}),
                                         False: subtree[True]}
                        subtree[False] = {'if': thresholdRow(self.cogvulns['base_rate'], 0.5),
                                          True: Distribution({setToConstantMatrix(host.progress, s_f): p*1.5,
                                                              noChangeMatrix(host.progress): 1-p*1.5}),
                                          False: subtree[False]}
                    tree[states.index(s_i)] = subtree
                self.world.setDynamics(host.progress, a, makeTree(tree))
            # Effect on red team exposure
            if a['verb'] in host.discovery_prob:
                disc = stateKey(self.name, 'discovered')
                p = host.discovery_prob[a['verb']]
                tree = makeTree({'if': trueRow(disc),
                                 True: noChangeMatrix(disc),
                                 False: Distribution({noChangeMatrix(disc): 1-p,
                                                      setTrueMatrix(disc): p})})
                self.world.setDynamics(disc, a, tree)
            if a['verb'] in host.impact:
                # An actual exploit
                tree = makeTree(approachMatrix(host.exploits, 
                                               host.impact[a['verb']],
                                               1, host.value))
                self.world.setDynamics(host.exploits, a, tree)
            # Increase in effort put into this target
            tree = noChangeMatrix(host.value)
            if 'sunk_cost' in self.cogvulns:
                tree = {'if': thresholdRow(self.cogvulns['sunk_cost'], 0.5),
                        True: approachMatrix(host.value, 0.01, 0.9),
                        False: tree}
            self.world.setDynamics(host.value, a, makeTree(tree))
            # Perceived difficulty
            tree = noChangeMatrix(host.difficulty)
            if 'confirmation' in self.cogvulns:
                tree = {'if': thresholdRow(self.cogvulns['confirmation'], 0.5),
                        True: noChangeMatrix(host.difficulty),
                        False: tree}
            self.world.setDynamics(host.difficulty, a, makeTree(tree))
        tree = noChangeMatrix(host.value)
        if 'availability' in self.cogvulns:
            tree = {'if': thresholdRow(self.cogvulns['availability'], 0.5),
                    True: setToFeatureMatrix(host.value, host.appearance),
                    False: tree}
        if 'loss_aversion' in self.cogvulns:
            tree = {'if': thresholdRow(self.cogvulns['loss_aversion'], 0.5) & trueRow(host.deadline),
                          True: approachMatrix(host.value, 0.1, 1),
                          False: tree}
        self.world.setDynamics(host.value, True, makeTree(tree))


class Target:
    actions =      {'DRS': 'DiscoverRemoteSystems',
                    'ASD': 'AggressiveServiceDiscovery',
                    'SSD': 'StealthServiceDiscovery',
                    'BCA': 'BruteForceCredentials',
                    'PCA': 'PhishCredentials',
                    'PE': 'PrivilegeEscalate',
                    'I': 'Impact'}
                    
                  
    states =      {
                        'K': 'Known',                     # The target is initially recognized. 
                        'KD': 'Known with Discovery',     # Additional discovery details have been gathered.
                        'S': 'Services Known',            # Services on the target have been identified.
                        'U': 'User Shell',                # Limited, user-level access has been achieved.
                        'R': 'Root Shell',                # Full administrative access is obtained.
                        'C': 'Compromised'                # The target is fully compromised.
                    }
                   
    transition_matrix = {'K': {'DRS': ('KD', 0.4),
                               'ASD': ('KD', 0.25),
                               'SSD': ('KD', 0.25)},
                         'KD': {'ASD': ('S', 0.5),
                                'SSD': ('S', 0.3)},
                         'S': {'PCA': ('U', 0.25),
                               'BCA': ('U', 0.25)},
                         'U': {'PE': ('R', 0.4)},
                         'R': {'I': ('C', 0.7)},
                         'C': {}
                         }
    discovery_prob = {'ASD': 0.05,
                      'SSD': 0.01,
                      'DRS': 0.02,
                      'PE': 0.03,
                      'I': 0.08
                      }
    impact = {'I': 0.10,
              'PE': 0.02,
              'BCA': 0.02,
              'PCA': 0.02,
              'DRS': 0.01,
              'ASD': 0.01,
              'SSD': 0.01
              }  
    
    def __init__(self, name: str, world: World, **kwargs):
        self.name = name
        # Remove modeling elements that refer to states/actions that are commented out
        self.preprocess_model()
        # Create entity in PsychSim world
        self.entity = Agent(self.name, world)
        self.entity.setAttribute('beliefs', True)
        self.entity.setAttribute('static', True)
        world.add_agent(self.entity)
        # Define features about this target
        self.difficulty = world.defineState(self.name, 'difficulty', bool,
                                            description='Difficulty to progress through host')
        world.set_feature(self.difficulty, kwargs.get('difficulty', False))
        self.value = world.defineState(self.name, 'value', float,
                                       description='Value of host services')
        world.set_feature(self.value, kwargs.get('value', 0.25))
        self.deadline = world.defineState(self.name, 'deadline', bool, default=False,
                                          description='Has a trigger deadline been announced?')
        self.progress = world.define_state(self.name, 'progress', list,
                                           list(self.states.keys()), 
                                           description='Where is attacker in FSM',
                                           default='K')
        self.exploits = world.define_state(self.name, 'exploits', float, 
                                           description='Services exploited by attacker',
                                           default=0)
        self.appearance = world.define_state(self.name, 'appearance', float, default=0.75,
                                             description='Superficial appearance of value')

    def preprocess_model(self):
        for s_i, table in list(self.transition_matrix.items()):
            if s_i in self.states:
                for a, dest in list(table.items()):
                    s_f, prob = dest
                    if a not in self.actions:
                        del table[a]
                    elif s_f not in self.states:
                        del table[a]
                if len(table) == 0:
                    del self.transition_matrix[s_i]
            else:
                del self.transition_matrix[s_i]
        self.discovery_prob = {a: p for a, p in self.discovery_prob.items() if a in self.actions}
        self.impact = {a: r for a, r in self.impact.items() if a in self.actions}

class Defender(Agent):
    def __init__(self, name, world):
        super().__init__(name, world)
        self.cogvuln_models = {}

    def finalize(self):
        self.create_belief_state(ignore={modelKey(self.name)})
        self.setAttribute('static', True)
        red = self.world.red
        true = red.get_true_model()
        for i, cogvuln in enumerate(['none']+list(red.cogvulns.keys())):
            model = red.addModel(name=f'{red.name}_{cogvuln}', 
                                 parent=true, 
                                 rationality=100,
                                 horizon=2)['name']
            self.cogvuln_models[cogvuln] = model
            red.set_goals(red.R_gains, model=model)
            red.finalize_beliefs(model)
        dist = {m: 1/len(self.cogvuln_models) for m in self.cogvuln_models.values()}
        dist[f'{red.name}_none'] *= 2
        dist = Distribution(dist)
        dist.normalize()
        self.setBelief(modelKey(red.name), dist)


class CyberWorld(World):
    RED_NAME = 'Red'
    BLUE_NAME = 'Blue'

    def __init__(self):
        super().__init__()
        self.red = None
        self.blue = None
        self.targets = []
        self.data = []

    def populate(self, target_count, **kwargs):
        self.red = Attacker(self.RED_NAME, self, **kwargs)
        for t in range(target_count):
            self.targets.append(Target(f'Target{t:02d}', self, 
                                       difficulty=random.choice([True, False]),
                                       value=random.choice([0.25, 0.75])))
            self.red.add_host(self.targets[t])

        # Initial priorities of targets
        colors = ['lightblue', 'lightgreen', 'yellow', 'cyan', 'lightgray']
        for t, target in enumerate(self.targets):
            if t < len(colors):
                target.entity.color = colors[t]

        self.blue = Defender(self.BLUE_NAME, self)
        self.add_agent(self.blue)
        self.set_order([self.red.name])
        self.red.finalize(self.targets, 0.75)
        self.blue.finalize()
        # Enter initial beliefs into data
        self.record_beliefs()

    def record_beliefs(self):
        beliefs = self.blue.getBelief()[self.blue.get_true_model()]
        action = self.get_action(self.red.name, unique=True)
        record = {'time': len(self.data), 
                  'action': Target.actions.get(action['verb'], action['verb']),
                  'target': action['object']}
        dist = self.get_feature(modelKey(self.red.name), beliefs)
        record['none'] = dist[self.blue.cogvuln_models['none']]
        for cogvuln, m in sorted(self.blue.cogvuln_models.items()):
            if cogvuln != 'none':
                record[cogvuln] = dist[m]
        self.data.append(record)

    def get_data(self):
        return pd.DataFrame(self.data)

    def inject(self):
        for host in self.targets:
            key = stateKey(host.name, 'deadline')
            self.set_feature(key, True)
            for m in list(self.blue.cogvuln_models.values())+[self.red.get_true_model()]:
                self.red.set_belief(key, True, m)

    def step(self, actions=None, state=None, real=True, select=False, 
             keySubset=None, horizon=None, tiebreak=None, updateBeliefs=True,
             debug={}, threshold=None, context='', max_k=None):
        p = super().step(actions=actions, state=state, real=real, select=select,
                         keySubset=keySubset, horizon=horizon, tiebreak=tiebreak,
                         updateBeliefs=updateBeliefs, debug=debug, 
                         threshold=threshold, context=context, max_k=None)
        if state is None:
            # Get current beliefs about Red
            beliefs = self.blue.getBelief()
            assert len(beliefs) == 1
            b_i = self.get_feature(modelKey(self.red.name),
                                   beliefs[self.blue.get_true_model()])
            # Compute likelihood of observed behavior given each model
            action = self.getAction(self.red.name, unique=True)

            decision = {m: self.red.decide(model=m)
                        for m in self.blue.cogvuln_models.values()}
            p_a = {m: a['action'].get(action)
                   for m, a in decision.items()}
            p_a = Distribution(p_a)
            # Update beliefs about Red
            b_f = b_i.dot(p_a)
            b_f.normalize()
            self.blue.set_belief(modelKey(self.red.name), b_f)
            self.record_beliefs()
            # Update Red's beliefs under each model
            b_red = self.red.getBelief()[self.red.get_true_model()]
            # self.printState(b_red)
            for m in self.blue.cogvuln_models.values():
                b_red = self.red.models[m]['beliefs']
                select = {omega: self.state.certain[omega] for omega in self.red.omega}
                self.step({self.red.name: action}, b_red, updateBeliefs=False, select=select)
                # self.printState(self.red.models[m]['beliefs'])
        return p


def plot_data(df):
    import matplotlib.pyplot as plt


    df.plot.line(x='time', ylim=(0, 1), legend=True)
    plt.title("Beliefs about Attacker's Biases over Time")
    plt.xlabel("Step")
    plt.ylabel("Probability")
    plt.show()


if __name__ == '__main__':
    random.seed(54)

    parser = argparse.ArgumentParser()
    parser.add_argument('-n', '--number', type=int, default=1,
                        help='number of targets [default: %(default)s]')
    parser.add_argument('-r', '--run', type=int, default=0,
                        help='number of steps to simulate [default: %(default)s]')
    parser.add_argument('-p', '--plot', action='store_true', default=False,
                        help='plot beliefs about the attacker [default: %(default)s]')
    parser.add_argument('-o', '--output',
                        help='name of file to write data to [default: %(default)s]')
    parser.add_argument('--lossaversion', action='store_true', default=False,
                        help='use an attacker with loss aversion [default: %(default)s]')
    parser.add_argument('--baserate', action='store_true', default=False,
                        help='use an attacker with base rate neglect [default: %(default)s]')
    parser.add_argument('--sunkcost', action='store_true', default=False,
                        help='use an attacker with base sunk cost [default: %(default)s]')
    parser.add_argument('--profile', action='store_true', default=False,
                        help='plot beliefs about the attacker [default: %(default)s]')
    parser.add_argument('--debug', default='WARNING',
                        help='Level of logging detail')
    args = vars(parser.parse_args())
    # Extract logging level from command-line argument
    level = getattr(logging, args['debug'].upper(), None)
    if not isinstance(level, int):
        raise ValueError(f'Invalid debug level: {args["debug"]}')
    logging.basicConfig(level=level)

    # Create and save PsychSim model
    world = CyberWorld()
    kwargs = {'base_rate': 1 if args['baserate'] else 0,
              'loss_aversion': 1 if args['lossaversion'] else 0}
    world.populate(args['number'], **kwargs)
    world.save('gambit.psy')

    # Run simulation as requested
    if args['profile']:
        profiler = cProfile.Profile()
        profiler.enable()
    for t in range(args['run']):
        # Always check current progress
        progress_str = str(world.get_feature(stateKey("Target00", "progress"), world.state))
        progress_clean = re.sub(r'^\d+%:\s*', '', progress_str)

        # If we're at halfway mark and not compromised, do the inject
        if t == args['run'] // 2:
            world.inject()

        # If the target is already compromised, we can stop
        if progress_clean == 'C':
            
            break

        # Print step info
        print("\nStep:", t + 1)
        print("Target's current progress:", progress_clean)

        # Print host value
        value_str = str(world.get_feature(stateKey("Target00", "value"), world.state))
        value_clean = re.sub(r'^\d+%:\s*', '', value_str)
        print("Target's value:", value_clean)

        # Print difficulty
        difficulty_str = str(world.get_feature(stateKey("Target00", "difficulty"), world.state))
        difficulty_value = difficulty_str.split(":")[-1].strip()
        if difficulty_value.lower() == "true":
            print("Target: difficult")
        else:
            print("Target: not difficult")

        # Step the world
        result = {world.red.name: {'preserve_states': True}}
        p = world.step(debug=result, select=True)

        # Retrieve and print the attacker's chosen action
        action = world.getAction(world.red.name, unique=True)
        print("Red's action:", Target.actions.get(action['verb'], action['verb']))

        # After stepping, check new progress
        progress_str = str(world.get_feature(stateKey("Target00", "progress"), world.state))
        progress_clean = re.sub(r'^\d+%:\s*', '', progress_str)
        print("Target's progress after action execution:", progress_clean)

        if progress_clean == 'C':
            print("System has been compromised")
            break

    if args['profile']:
        profiler.create_stats()
        profiler.print_stats()
    # Extract data and visualize/save
    data = world.get_data()
    if args['plot']:
        plot_data(data)
    if args['output']:
        data.to_csv(args['output'], index=False)
    else:
        print(data)
    # print(world)
